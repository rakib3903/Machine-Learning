{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NQTQc67v4z4u",
        "outputId": "ab335e55-78d4-45db-e50b-2d8a32580627"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            " [1 0 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 1 1 1 1 1 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 0 0 1 1 1 1 0 0 0]\n",
            " [0 1 0 0 0 0 0 0 0 0 0 1 0 0 1 1 1]]\n",
            "Test Text: buy now cheap offer\n",
            "Prediction: Spam\n"
          ]
        }
      ],
      "source": [
        "from sklearn.naive_bayes import MultinomialNB\n",
        "import numpy as np\n",
        "\n",
        "texts = [\n",
        "    \"buy cheap now\",\n",
        "    \"limited offer buy now\",\n",
        "    \"let's go to the park\",\n",
        "    \"are you free tomorrow\",\n",
        "    \"cheap deal just for you\"\n",
        "]\n",
        "labels = [1, 1, 0, 0, 1]\n",
        "\n",
        "\n",
        "def tokenize(text):\n",
        "    return text.lower().split()\n",
        "\n",
        "\n",
        "all_words = []\n",
        "for sentence in texts:\n",
        "    words = tokenize(sentence)\n",
        "    for word in words:\n",
        "        if word not in all_words:\n",
        "            all_words.append(word)\n",
        "\n",
        "\n",
        "word_to_index = {}\n",
        "for index, word in enumerate(all_words):\n",
        "    word_to_index[word] = index\n",
        "\n",
        "\n",
        "\n",
        "def text_to_vector(text):\n",
        "    vector = [0] * len(all_words)\n",
        "    for word in tokenize(text):\n",
        "        if word in word_to_index:\n",
        "            position = word_to_index[word]\n",
        "            vector[position] += 1\n",
        "    return vector\n",
        "\n",
        "X = []\n",
        "for sentence in texts:\n",
        "    X.append(text_to_vector(sentence))\n",
        "\n",
        "\n",
        "X = np.array(X)\n",
        "y = np.array(labels)\n",
        "\n",
        "print(X)\n",
        "\n",
        "model = MultinomialNB()\n",
        "model.fit(X, y)\n",
        "\n",
        "test_text = \"buy now cheap offer\"\n",
        "test_vector = np.array([text_to_vector(test_text)])\n",
        "prediction = model.predict(test_vector)\n",
        "\n",
        "print(\"Test Text:\", test_text)\n",
        "print(\"Prediction:\", \"Spam\" if prediction[0] == 1 else \"Ham\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "texts = [\n",
        "    \"buy cheap now\",\n",
        "    \"limited offer buy now\",\n",
        "    \"let's go to the park\",\n",
        "    \"are you free tomorrow\",\n",
        "    \"cheap deal just for you\",\n",
        "    \"do you want to play football\",\n",
        "    \"click here to win a prize\",\n",
        "    \"meeting at 5 pm\",\n",
        "    \"urgent offer limited time\",\n",
        "    \"see you tomorrow at school\"\n",
        "]\n",
        "\n",
        "labels = [1, 1, 0, 0, 1, 0, 1, 0, 1, 0]\n",
        "\n",
        "# Tokenize\n",
        "def tokenize(text):\n",
        "    return text.lower().split()\n",
        "\n",
        "# Build vocabulary\n",
        "all_words = []\n",
        "for sentence in texts:\n",
        "    for word in tokenize(sentence):\n",
        "        if word not in all_words:\n",
        "            all_words.append(word)\n",
        "\n",
        "word_to_index = {word: idx for idx, word in enumerate(all_words)}\n",
        "\n",
        "# Convert text to vector\n",
        "def text_to_vector(text):\n",
        "    vector = [0] * len(all_words)\n",
        "    for word in tokenize(text):\n",
        "        if word in word_to_index:\n",
        "            vector[word_to_index[word]] += 1\n",
        "    return vector\n",
        "\n",
        "# Vectorize data\n",
        "X = np.array([text_to_vector(text) for text in texts])\n",
        "y = np.array(labels)\n",
        "\n",
        "# Train-test split\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.3, random_state=42\n",
        ")\n",
        "\n",
        "# Train model\n",
        "model = MultinomialNB()\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Predict on test set\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "# Accuracy\n",
        "acc = accuracy_score(y_test, y_pred)\n",
        "print(\"Accuracy on test set:\", round(acc * 100, 2), \"%\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ttGwj892-rtr",
        "outputId": "02b349c0-9e2e-4be6-8c5d-bf75b384150d"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy on test set: 100.0 %\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.datasets import fetch_20newsgroups\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.metrics import accuracy_score\n",
        "import numpy as np\n",
        "\n",
        "# Step 1: Load a subset of newsgroup categories to keep it simple\n",
        "categories = ['sci.med', 'comp.graphics']\n",
        "newsgroups = fetch_20newsgroups(subset='all', categories=categories, remove=('headers', 'footers', 'quotes'))\n",
        "\n",
        "texts = newsgroups.data\n",
        "labels = newsgroups.target\n",
        "\n",
        "\n",
        "# print(\"Article 1 (label:\", newsgroups.target_names[labels[0]], \"):\")\n",
        "# print(texts[0])\n",
        "# print(\"\\n\" + \"=\"*80 + \"\\n\")\n",
        "\n",
        "# # Print the second input text and its label\n",
        "# print(\"Article 2 (label:\", newsgroups.target_names[labels[1]], \"):\")\n",
        "# print(texts[1])\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def tokenize(text):\n",
        "    return text.lower().split()\n",
        "\n",
        "\n",
        "vocab = []\n",
        "for text in texts:\n",
        "    for word in tokenize(text):\n",
        "        if word not in vocab:\n",
        "            vocab.append(word)\n",
        "\n",
        "\n",
        "word_to_index = {word: i for i, word in enumerate(vocab)}\n",
        "\n",
        "\n",
        "def text_to_vector(text):\n",
        "    vector = [0] * len(vocab)\n",
        "    for word in tokenize(text):\n",
        "        if word in word_to_index:\n",
        "            idx = word_to_index[word]\n",
        "            vector[idx] += 1\n",
        "    return vector\n",
        "\n",
        "\n",
        "X = np.array([text_to_vector(text) for text in texts])\n",
        "y = np.array(labels)\n",
        "\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.3, random_state=42\n",
        ")\n",
        "\n",
        "\n",
        "model = MultinomialNB()\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "\n",
        "y_pred = model.predict(X_test)\n",
        "acc = accuracy_score(y_test, y_pred)\n",
        "print(\"Accuracy:\", round(acc * 100, 2), \"%\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vuBvxVeKA1O3",
        "outputId": "e0de721d-d7b0-415d-b6af-4f7e5688c8e2"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 94.91 %\n"
          ]
        }
      ]
    }
  ]
}